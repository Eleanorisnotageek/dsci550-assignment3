{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d4400c",
   "metadata": {},
   "source": [
    "# Solr Setup for Haunted Places Dataset (Assignment 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edbd73",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This section documents the process for setting up Apache Solr and ingesting the Haunted Places dataset for DSCI 550 Assignment 3. \n",
    "\n",
    "We created a Solr core named `assignment3`, uploaded the processed JSON dataset, and exported the core as a `.tgz` file for submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9e634",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "### 1. Start Solr via Docker\n",
    "We pulled the latest Solr Docker image and started a Solr container.\n",
    "\n",
    "```bash\n",
    "docker pull solr\n",
    "docker run -d -p 8983:8983 --name solr-container solr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4bc0e2",
   "metadata": {},
   "source": [
    "### 2. Create a Core\n",
    "We created a new Solr core called assignment3.\n",
    "\n",
    "```bash\n",
    "docker exec -it solr-container solr create_core -c assignment3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffe5fb5",
   "metadata": {},
   "source": [
    "### 3. Convert TSV to Solr-compatible JSON Array\n",
    "We wrote a Python script to convert the original final_haunted_places.tsv file into a properly formatted JSON array for Solr ingestion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d91df8",
   "metadata": {},
   "source": [
    "### 4. Ingest JSON into Solr\n",
    "We posted the JSON array into Solr using curl and specified json.array=true.\n",
    "After uploading, we verified the data in Solr Admin UI by querying: \"*:*\"\n",
    "The Haunted Places data should appear correctly.\n",
    "\n",
    "```bash\n",
    "curl 'http://localhost:8983/solr/assignment3/update?commit=true&json.array=true' --header \"Content-Type: application/json\" --data-binary @Dataset/final_haunted_places_array.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4760a505",
   "metadata": {},
   "source": [
    "### 5. Save the Core\n",
    "We exported the Solr core assignment3 to a .tgz archive. \n",
    "\n",
    "```bash\n",
    "docker exec -it solr-container tar czf /var/solr/data/assignment3.tgz /var/solr/data/assignment3\n",
    "docker cp solr-container:/var/solr/data/assignment3.tgz 3_ApacheSolr-ElasticSearch/\n",
    "```\n",
    "\n",
    "And we confirmed the archive contents using:\n",
    "```bash\n",
    "tar -tzf 3_ApacheSolr-ElasticSearch/assignment3.tgz\n",
    "```\n",
    "\n",
    "And the archive contains all necessary config and index files for restoring the core.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b673a",
   "metadata": {},
   "source": [
    "# Instructions to Restore Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6de46d5",
   "metadata": {},
   "source": [
    "1. Start a Solr container.\n",
    "2. Copy the .tgz archive into the container:\n",
    "\n",
    "    ```bash\n",
    "    docker cp assignment3.tgz solr-container:/var/solr/data/\n",
    "    ```\n",
    "3. SSH into the container and extract:\n",
    "\n",
    "    ```bash\n",
    "    docker exec -it solr-container bash\n",
    "    cd /var/solr/data/\n",
    "    tar -xzf assignment3.tgz\n",
    "    exit\n",
    "    docker restart solr-container\n",
    "    ```\n",
    "The assignment3 core will be restored and available at http://localhost:8983/solr/#/assignment3/query.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccfa32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "543477b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tsv = '../Dataset/final_haunted_places.tsv'\n",
    "output_json = '../Dataset/final_haunted_places_array.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f190839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TSV\n",
    "data = []\n",
    "with open(input_tsv, mode='r', encoding='utf-8') as tsv_file:\n",
    "    reader = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        clean_row = {k: v for k, v in row.items() if v != ''}\n",
    "        data.append(clean_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cf4c047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully created ../Dataset/final_haunted_places_array.json (in array format)\n"
     ]
    }
   ],
   "source": [
    "# Write as a JSON Array\n",
    "with open(output_json, mode='w', encoding='utf-8') as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "\n",
    "print(f\" Successfully created {output_json} (in array format)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae17eb49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
